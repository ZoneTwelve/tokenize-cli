# ğŸ§© Tokenize CLI

An easy-to-use command-line tool for **tokenizing text files or folders** using [ğŸ¤— Hugging Face Transformers](https://huggingface.co/docs/transformers).
Ideal for quick inspection of token counts, model comparisons, or debugging chat templates.

---

## ğŸ“ TODO

* Tokenize a folder to parse all the file inside that folder using dataset library
* Visualize the number with scientific notation
* List the special tokens in the context

---

## ğŸš€ Features

* ğŸ”¤ Tokenize any text file with your favorite Hugging Face tokenizer
* ğŸ§® Count **special**, **non-special**, and **total tokens**
* ğŸ’¬ Apply chat templates to structured JSON conversation files
* âš™ï¸ Persist your tokenizer configuration in a simple local JSON file
* âš¡ Uses `fire` for a fast CLI and Hugging Face `transformers` under the hood
* ğŸª¶ Minimal setup â€” zero boilerplate

---

## ğŸ“¦ Installation

You can install Tokenize CLI using [**uv**](https://github.com/astral-sh/uv), a modern, lightning-fast Python package manager.

### ğŸ”§ Quick Install

```bash
uv pip install tokenize-cli
```

### ğŸ§© Install from Local Directory

If you have cloned the repository locally:

```bash
uv pip install .
```

### ğŸŒ€ Install Directly from GitHub

```bash
uv pip install git+https://github.com/ZoneTwelve/tokenize-cli.git
```

### ğŸ§‘â€ğŸ’» Development Install

If youâ€™re working on the project locally (editable mode):

```bash
uv pip install -e .
```

---

## ğŸ§  Usage

### 1ï¸âƒ£ Configure Your Tokenizer

Before tokenizing any files, set your preferred model:

```bash
tokenize-cli --model google/gemma-3-270m-it
```

Inspect your current configuration:

```bash
tokenize-cli
```

Example output:

```
ğŸ“„ Current config: {'tokenizer_model': 'google/gemma-3-270m-it'}
```

---

### 2ï¸âƒ£ Tokenize a Text File

Use the `tokenize` command to analyze a file:

```bash
tokenize file path/to/file.txt
```

Example output:

```
ğŸ”¤ Using tokenizer: google/gemma-3-270m-it
ğŸ“„ Tokenizing file: example.txt
âœ… Tokenization complete.
ğŸ§© Special tokens    : 3
ğŸ”¡ Non-special tokens: 197
ğŸ”¢ Total tokens      : 200
```

---

### 3ï¸âƒ£ Apply Chat Templates

For chat-style data (like `messages.json`):

```bash
tokenize chat examples/messages.json
```

To tokenize the resulting text and count total tokens:

```bash
tokenize chat examples/messages.json --tokenize True
```

Optionally, save the chat-rendered text to a file:

```bash
tokenize chat examples/messages.json --save chat_output.txt
```

---

## ğŸ§° Command Reference

| Command        | Description                             |
| -------------- | --------------------------------------- |
| `tokenize`     | Tokenize text files and count tokens    |
| `tokenize-cli` | Configure or inspect tokenizer settings |

Example commands:

```bash
# Configure model
tokenize-cli --model google/gemma-3-270m-it

# Tokenize plain text file
tokenize file my_text.txt

# Apply chat template
tokenize chat examples/messages.json

# Tokenize chat template output
tokenize chat examples/messages.json --tokenize True
```

---

## ğŸ§© Example Data

Example chat file: `examples/messages.json`

```json
[
  {"role": "system", "content": "You are an tokenizer."},
  {"role": "user", "content": "This is an easy to use tokenize CLI"},
  {"role": "assistant", "content": "You are 100% correct, this is an easy to use tokenize CLI and I hope you like it."}
]
```

---

## ğŸ§‘â€ğŸ’» Development

Clone and install with `uv`:

```bash
git clone https://github.com/ZoneTwelve/tokenize-cli.git
cd tokenize-cli
uv pip install -e .
```

Run locally:

```bash
python src/main.py file examples/messages.json
```

Or configure the tokenizer:

```bash
python src/cli.py --model Qwen/Qwen3-0.6B
```

---

## âš–ï¸ License

This project is licensed under the **GNU Affero General Public License v3.0**.
See the [LICENSE](LICENSE) file for details.
